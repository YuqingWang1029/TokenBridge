<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="TokenBridge: Bridging Continuous and Discrete Tokens for Autoregressive Visual Generation">
  <meta name="keywords" content="TokenBridge, Visual Generation, Autoregressive Models, Image Generation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>TokenBridge: Bridging Continuous and Discrete Tokens for Visual Generation</title>

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-QCJY998LVV"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
  
    gtag('config', 'G-QCJY998LVV');
  </script>
  
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="stylesheet" href="https://unpkg.com/aos@next/dist/aos.css" />

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <style>
    .card-image video {
      width: 150%;
      height: 150%;
      object-fit: cover;
    }
    .gif-card .card-image {
      padding: 0;
      display: flex;
      justify-content: center;
    }
    .gif-card .card-image img {
      object-fit: cover;
    }
    .gif-card .card-content {
      width: 100%;
    }
    .smaller-text {
      font-size: 0.8rem;
    }
    .smallest-text {
      font-size: 0.5rem;
    }
    .section-divider {
      border-top: 1px solid #dbdbdb;
      margin-top: 3rem;
      margin-bottom: 3rem;
    }
    .wider-video-container {
      max-width: 1600px !important;
      width: 90% !important;
      margin-left: auto;
      margin-right: auto;
    }
    .wider-column {
      padding: 0.75rem;
    }

    /* 贡献点的醒目样式 */
    .contribution-item {
      color: #0074D9;  /* 鲜明的蓝色 */
      font-weight: 600;
      padding: 10px 15px;
      background-color: #f8f9ff;  /* 淡蓝色背景 */
      border-radius: 8px;
      border-left: 4px solid #0074D9;  /* 左侧蓝色边框 */
      margin-bottom: 15px !important;
      transition: all 0.3s ease;
    }

    .contribution-item:hover {
      background-color: #f0f4ff;
      transform: translateX(5px);
    }
    
    /* 章节标题样式 - 移除下划线和悬停效果 */
    .title.is-3 {
      color: #0074D9;
      margin-bottom: 1.5rem;
    }
    
    /* 统一图片风格 - 与背景融合 */
    .content img, .method-figure {
      width: 100%;
      max-width: 900px;
      margin: 0 auto 1.5rem auto;
      display: block;
      box-shadow: none; /* 移除阴影使其与背景融合 */
      border-radius: 4px; /* 轻微圆角使外观更柔和 */
      background-color: transparent; /* 确保背景透明 */
      transition: transform 0.3s ease;
    }
    
    /* 特殊处理尺寸较小的图片 */
    .method-figure.small-figure {
      width: 60%;
      max-width: 700px;
    }

    /* 特殊处理宽大的图片 */
    .full-width-figure {
      width: 100% !important;
      max-width: none !important;
    }
    
    /* 导航栏改进 */
    .navbar {
      position: sticky;
      top: 0;
      z-index: 100;
      box-shadow: 0 2px 4px rgba(0,0,0,0.1);
      background-color: rgba(255, 255, 255, 0.95);
      transition: all 0.3s ease;
    }
    
    /* 引用和强调的优化 */
    strong {
      color: #0074D9;
      font-weight: 600;
    }
    
    blockquote {
      border-left: 4px solid #0074D9;
      background-color: #f8f9ff;
      padding: 15px;
      margin: 20px 0;
      border-radius: 4px;
    }
    
    /* 致谢样式 */
    .acknowledgment {
      color: #000000;
      text-align: left;
      margin-top: 2rem;
      font-size: 1rem;
    }
  </style>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://yuqingwang1029.github.io/Loong-video/">
            Loong
          </a>
          <a class="navbar-item" href="https://yuqingwang1029.github.io/PAR/">
            PAR
          </a>
          <a class="navbar-item" href="#">
            TokenBridge
          </a>
        </div>
      </div>
    </div>
  </div>
</nav>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">TokenBridge: Bridging Continuous and Discrete Tokens for Visual Generation</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=QC7nNe0AAAAJ&hl=zh-CN">Yuqing Wang</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=xXMj6_EAAAAJ&hl=zh-CN">Zhijie Lin</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://tyshiwo1.github.io/">Yao Teng</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://yuanzhi-zhu.github.io/about/">Yuanzhi Zhu</a><sup>3</sup>,</span>
            <span class="author-block">
              <a href="https://renshuhuai-andy.github.io/">Shuhuai Ren</a><sup>4</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com.sg/citations?user=Q8iay0gAAAAJ&hl=zh-CN">Jiashi Feng</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://xh-liu.github.io/">Xihui Liu</a><sup>1*</sup></span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Hong Kong,</span>
            <span class="author-block"><sup>2</sup>ByteDance Seed,</span>
            <span class="author-block"><sup>3</sup>École Polytechnique,</span>
            <span class="author-block"><sup>4</sup>Peking University</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- arXiv Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/" target="_blank">
                  <span class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/yuqingwang1029/TokenBridge" target="_blank">
                  <span class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Teaser image - 只放大图片尺寸 -->
<section class="hero teaser">
  <div class="container" style="max-width: 1200px;"> <!-- 增加容器宽度 -->
    <div class="hero-body">
      <div class="has-text-centered" data-aos="fade-up">
        <img src="./static/images/vis.svg" alt="TokenBridge Teaser" style="width: 100%; max-width: none;"> <!-- 放大图片 -->
      </div>
      <h2 class="subtitle has-text-centered" data-aos="fade-up" data-aos-delay="200">
        TokenBridge combines the representational capacity of continuous tokens with the modeling simplicity of discrete approaches for high-quality visual generation.
      </h2>
    </div>
  </div>
</section>

<!-- Main Contributions Section -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 has-text-centered" data-aos="fade-up">Main Contributions</h2>
        <div class="content">
          <ul style="list-style-type: none; padding: 0;">
            <li class="is-size-5 mb-4 has-text-left contribution-item" data-aos="fade-up" data-aos-delay="100">A novel paradigm that successfully bridges continuous and discrete token representations, achieving continuous level visual quality with the modeling simplicity of standard autoregressive cross-entropy loss.</li>
            <li class="is-size-5 mb-4 has-text-left contribution-item" data-aos="fade-up" data-aos-delay="200">A training-free quantization approach that transforms pretrained VAE features into discrete tokens without the optimization instabilities of conventional discrete tokenizers, while preserving original visual fidelity.</li>
            <li class="is-size-5 mb-4 has-text-left contribution-item" data-aos="fade-up" data-aos-delay="300">An efficient dimension-wise autoregressive prediction mechanism that handles exponentially large token spaces without computational explosion, enabling fine-grained token representation without sacrificing modeling feasibility.</li>
          </ul>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Comparison Section -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 has-text-centered" data-aos="fade-up">Comparison of different AR approaches</h2>
        <div class="content">
          <!-- Method comparison figure -->
          <div class="has-text-centered" data-aos="fade-up" data-aos-delay="100">
            <img src="./static/images/compare.svg" alt="Method Comparison" class="method-figure">
          </div>
          
          <div class="content has-text-justified mt-4" data-aos="fade-up" data-aos-delay="150">
            <p>
               (a) Traditional discrete tokenization incorporates quantization during training, resulting in tokenizer training instability and limited vocabulary size that restricts representational capacity. (b) Hybrid continuous AR models preserve rich visual information but need complex distribution modeling (diffusion or GMM) beyond standard categorical prediction. (c) Our approach bridges these paradigms by applying post-training quantization to pretrained continuous features, maintaining the high representational capacity of continuous tokens while enabling simple autoregressive modeling.
            </p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Abstract -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 has-text-centered" data-aos="fade-up">Abstract</h2>
        <div class="content has-text-justified" data-aos="fade-up" data-aos-delay="100">
          <p>
            Autoregressive visual generation models typically rely on tokenizers to compress images into tokens that can be predicted sequentially. A fundamental dilemma exists in token representation: discrete tokens enable straightforward modeling with standard cross-entropy loss, but suffer from information loss and tokenizer training instability; continuous tokens better preserve visual details, but require complex distribution modeling, complicating the generation pipeline. In this paper, we propose TokenBridge, which bridges this gap by maintaining the strong representation capacity of continuous tokens while preserving the modeling simplicity of discrete tokens.
          </p>
          <p>
            To achieve this, we decouple discretization from the tokenizer training process through post-training quantization that directly obtains discrete tokens from continuous representations. Specifically, we introduce a dimension-wise quantization strategy that independently discretizes each feature dimension, paired with a lightweight autoregressive prediction mechanism that efficiently model the resulting large token space. Extensive experiments show that our approach achieves reconstruction and generation quality on par with continuous methods while using standard categorical prediction. This work demonstrates that bridging discrete and continuous paradigms can effectively harness the strengths of both approaches, providing a promising direction for high-quality visual generation with simple autoregressive modeling.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Method Section -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 has-text-centered" data-aos="fade-up">Method</h2>
        
        <!-- Post-Training Quantization -->
        <h3 class="title is-4 has-text-centered mt-6" data-aos="fade-up">Post-Training Quantization</h3>
        <div class="content">
          <div class="has-text-centered" data-aos="fade-up" data-aos-delay="100">
            <img src="./static/images/quant.svg" alt="Post-Training Quantization Process" class="method-figure">
          </div>
          
          <div class="content has-text-justified mt-4" data-aos="fade-up" data-aos-delay="150">
            <p>
              <strong>Illustration of our post-training quantization process.</strong> The top row shows the pretrained continuous VAE tokenizer, mapping an input image to continuous latent features and reconstructing it through the decoder. Our post-training quantization process (middle) transforms these continuous features into discrete tokens by independently quantizing each channel dimension. The bottom-left shows how our approach preserves the original Gaussian-like distribution (purple curve) in discretized form (purple histogram). The right portion demonstrates the de-quantization process that maps indices back to continuous values for decoding.
            </p>
          </div>
        </div>
        
        <!-- Efficient Large-Vocabulary Token Modeling -->
        <h3 class="title is-4 has-text-centered mt-6" data-aos="fade-up">Efficient Large-Vocabulary Token Modeling</h3>
        <div class="content">
          <div class="has-text-centered" data-aos="fade-up" data-aos-delay="100">
            <img src="./static/images/token.svg" alt="Dimension-wise Autoregressive Prediction" class="method-figure small-figure">
          </div>
          
          <div class="content has-text-justified mt-4" data-aos="fade-up" data-aos-delay="150">
            <p>
              <strong>Our autoregressive generation process.</strong> At the spatial level, our model autoregressively generates tokens conditioning on previous positions. For each spatial location, we apply dimension-wise sequential prediction to efficiently handle the large token space. This approach decomposes the modeling of each token into a series of smaller classification problems while preserving essential inter-dimensional dependencies.
            </p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Experiments Section -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 has-text-centered" data-aos="fade-up">Experiments</h2>
        
        <!-- Main Results -->
        <h3 class="title is-4 has-text-centered mt-6" data-aos="fade-up">Main Results</h3>
        <div class="content">
          <div class="has-text-centered" data-aos="fade-up" data-aos-delay="100">
            <img src="./static/images/results.png" alt="Quantitative Comparison" class="method-figure">
          </div>
          
          <div class="content has-text-justified mt-4" data-aos="fade-up" data-aos-delay="150">
            <p>
              <strong>Comparison of visual generation methods on ImageNet 256×256.</strong> Our model achieves comparable performance to the best continuous token approach (MAR) while using standard categorical prediction in autoregressive modeling.
            </p>
          </div>
        </div>
        
        <!-- Properties of Our Tokenizer -->
        <h3 class="title is-4 has-text-centered mt-6" data-aos="fade-up">Properties of Our Tokenizer</h3>
        <div class="content">
          <div class="has-text-centered" data-aos="fade-up" data-aos-delay="100">
            <img src="./static/images/recons.svg" alt="Reconstruction Quality Comparison" class="method-figure">
          </div>
          
          <div class="content has-text-justified mt-4" data-aos="fade-up" data-aos-delay="150">
            <p>
              <strong>Reconstruction quality of typical continuous and discrete tokenizers.</strong> For discrete baselines, we use VQ from LlamaGen and LFQ from OpenMAGVIT2. Our method achieves reconstruction quality comparable to continuous VAE, preserving more fine details than traditional discrete tokenizers, especially in text and facial features.
            </p>
          </div>
          
          <!-- 添加不同粒度重建的结果图 -->
          <div class="has-text-centered mt-6" data-aos="fade-up" data-aos-delay="200">
            <img src="./static/images/recons_b.svg" alt="Different Granularity Reconstruction Results" class="method-figure">
          </div>
          
          <div class="content has-text-justified mt-4" data-aos="fade-up" data-aos-delay="250">
            <p>
              <strong>Different quantization granularity reconstruction results.</strong> Visual comparison showing reconstructions at varying quantization levels. While global structure remains preserved across all quantization levels, finer quantization (higher B values) better maintains details in textures and edges.
            </p>
          </div>
        </div>
        
        <!-- Properties of Our Generator -->
        <h3 class="title is-4 has-text-centered mt-6" data-aos="fade-up">Properties of Our Generator</h3>
        <div class="content">
          <div class="has-text-centered" data-aos="fade-up" data-aos-delay="100">
            <img src="./static/images/parallel.svg" alt="Token Prediction Strategy Comparison" class="method-figure">
          </div>
          
          <div class="content has-text-justified mt-4" data-aos="fade-up" data-aos-delay="150">
            <p>
              <strong>Token Prediction Strategy.</strong> Comparison of dimension-wise token prediction approaches. Top: Parallel prediction produces blurry, inconsistent images. Bottom: Our autoregressive approach sequentially predicts token dimensions, generating coherent, high-quality images. This highlights the interdependence of token dimensions and they cannot be predicted independently.
            </p>
          </div>
          
          <div class="has-text-centered mt-6" data-aos="fade-up" data-aos-delay="200">
            <img src="./static/images/confidence.svg" alt="Confidence-guided Generation" class="method-figure">
          </div>
          
          <div class="content has-text-justified mt-4" data-aos="fade-up" data-aos-delay="250">
            <p>
              <strong>Generation guided by token confidence.</strong> Our discrete token approach enables confidence-guided generation, producing clean foreground objects against simple backgrounds by prioritizing high-confidence tokens. This provides an advantage over continuous tokens, which lack explicit token-level confidence scores.
            </p>
          </div>
        </div>
        
        <!-- More Visualization Results -->
        <h3 class="title is-4 has-text-centered mt-6" data-aos="fade-up">More Visualization Results</h3>
        <section class="hero teaser">
          <div class="container" style="max-width: 1200px;">
            <div class="has-text-centered" data-aos="fade-up" data-aos-delay="100">
              <img src="./static/images/more.svg" alt="ImageNet Generation Results" style="width: 100%; max-width: none;">
            </div>
            
            <div class="content has-text-justified mt-4" data-aos="fade-up" data-aos-delay="150">
              <p>
                <strong>Class-conditional generation results on ImageNet.</strong> Our approach achieves high-quality generation with fine details and realistic textures across diverse object categories.
              </p>
            </div>
          </div>
        </section>
      </div>
    </div>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title is-3 has-text-centered" data-aos="fade-up">BibTeX</h2>
    <pre data-aos="fade-up" data-aos-delay="100"><code>coming soon~
</code></pre>

    <div class="acknowledgment" data-aos="fade-up" data-aos-delay="150">
      <h3>Acknowledgment</h3>
      <p>The authors are grateful to <a href="https://www.tianhongli.me/">Tianhong Li</a> for helpful discussions on MAR and to <a href="https://enjoyyi.github.io/">Yi Jiang</a> for valuable feedback on the early version of this work.</p>
    </div>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            The website template is borrowed from <a href="https://nerfies.github.io/">Nerfies</a> under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

<script src="https://unpkg.com/aos@next/dist/aos.js"></script>
<script>
  // 初始化AOS动画库
  document.addEventListener('DOMContentLoaded', function() {
    AOS.init({
      duration: 800,
      easing: 'ease',
      once: true
    });
  });

  // Handle navbar burger menu for mobile
  document.addEventListener('DOMContentLoaded', () => {
    const $navbarBurgers = Array.prototype.slice.call(document.querySelectorAll('.navbar-burger'), 0);
    if ($navbarBurgers.length > 0) {
      $navbarBurgers.forEach(el => {
        el.addEventListener('click', () => {
          const target = el.dataset.target;
          const $target = document.getElementById(target);
          el.classList.toggle('is-active');
          $target.classList.toggle('is-active');
        });
      });
    }
  });
</script>

</body>
</html>